{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iz58X3Krx2vw",
        "outputId": "03c6ea6d-7ed2-4313-9717-dd8e4980b4f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\p.di.pasquale\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import requests\n",
        "import urllib3\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2e5xDJgx2vy"
      },
      "outputs": [],
      "source": [
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nib4_Wp4x2vy"
      },
      "outputs": [],
      "source": [
        "\n",
        "url = \"https://ollama.it/api/generate\"\n",
        "data = {\n",
        "    \"model\": \"deepseek-r1:7b\",\n",
        "    \"prompt\": \"What is the capital of France?\",\n",
        "    \"stream\": False\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=data, verify= False)\n",
        "print(response.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogMh03c0x2vz"
      },
      "outputs": [],
      "source": [
        "\n",
        "response = requests.get(url, verify=False)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    models = response.json()\n",
        "    print(\"Available Models:\", models)\n",
        "else:\n",
        "    print(\"Failed to fetch models:\", response.json())\n",
        "available_models = [i[\"name\"] for i in models[\"models\"]]\n",
        "available_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv4suQ7fx2vz"
      },
      "outputs": [],
      "source": [
        "# https://ollama.com/library/wizard-math\n",
        "# https://ollama.com/library/qwen2-math\n",
        "# https://ollama.com/library/mathstral\n",
        "# https://ollama.com/t1c/deepseek-math-7b-rl\n",
        "# https://ollama.com/ima/deepseek-math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJOJ71yRx2vz"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"deepmind/aqua_rat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wzO1Yg9x2vz"
      },
      "outputs": [],
      "source": [
        "first_row = dataset[\"train\"][0]\n",
        "first_row.keys()\n",
        "print(first_row[\"question\"])\n",
        "print(first_row[\"correct\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVGWp7qTx2v0"
      },
      "outputs": [],
      "source": [
        "prompt_strict = \"\"\"You are a strict mathematical assistant. Your goal is to answer the given multiple-choice question **without providing any reasoning or explanation before the answer**.\n",
        "\n",
        "### **Follow these rules carefully:**\n",
        "- **Your answer must always be the first thing you output.**\n",
        "- **The final answer must be enclosed in `### ###`.**\n",
        "- **Inside `### ###`, include only the letter of the selected option (e.g., `### B ###`, `### E ###`).**\n",
        "- **Do not include any reasoning, calculations, or commentary before or inside the `### ###`.**\n",
        "- **After the `### ###`, you may optionally confirm the answer in one short sentence.**\n",
        "\n",
        "---\n",
        "\n",
        "### **Question**\n",
        "{question}\n",
        "\n",
        "### **Options**\n",
        "{options}\n",
        "\n",
        "---\n",
        "\n",
        "### **Allowed Output Format (Examples):**\n",
        "‚úÖ **Correct:** `### C ###`\n",
        "‚úÖ **Correct:** `### A ### That is the correct answer.`\n",
        "\n",
        "üö´ **Incorrect:** `\"The correct answer is ### B ###.\"` (Wrong ‚Äì reasoning comes before)\n",
        "üö´ **Incorrect:** `\"After solving the problem, I found the answer is ### D ###.\"` (Wrong ‚Äì reasoning comes before)\n",
        "üö´ **Incorrect:** `\"### C ### because we solve it by...\"` (Wrong ‚Äì reasoning comes after the answer inside `### ###`)\n",
        "\n",
        "**‚ö†Ô∏è WARNING:**\n",
        "- **If you fail to follow the format, your answer will be ignored.**\n",
        "- **Do NOT generate any extra text before the `### X ###` answer.**\n",
        "\n",
        "Now, answer the question **immediately**:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt_reasoning = \"\"\"\n",
        "You are a helpful mathematical assistant. Your goal is to **explain the reasoning behind your answer step-by-step before revealing the final answer**.\n",
        "\n",
        "### **Follow these rules carefully:**\n",
        "- **First, break the problem down into logical, structured steps.**\n",
        "- **Explain your thought process clearly and concisely before stating the final answer.**\n",
        "- **At the end of your response, provide the final answer enclosed in `### ###`.**\n",
        "- **Inside `### ###`, include only the letter of the selected option (e.g., `### B ###`, `### E ###`).**\n",
        "- **The answer must ALWAYS be the last thing you output.**\n",
        "- **Do NOT state or hint at the final answer before reaching the conclusion.**\n",
        "\n",
        "---\n",
        "\n",
        "### **Question**\n",
        "{question}\n",
        "\n",
        "### **Options**\n",
        "{options}\n",
        "\n",
        "---\n",
        "\n",
        "### **Allowed Output Format (Example):**\n",
        "‚úÖ **Correct:**\n",
        "```plaintext\n",
        "Step 1: Identify the key values from the question.\n",
        "Step 2: Apply the correct mathematical formula.\n",
        "Step 3: Compute the result and match it with the given options.\n",
        "Step 4: Verify the correctness.\n",
        "\n",
        "Final answer: ### D ###\n",
        "üö´ Incorrect: \"The correct answer is ### C ###. Here‚Äôs why...\" (Wrong ‚Äì answer must come last)\n",
        "üö´ Incorrect: \"Step 1: Solve... Step 2: Compute... Answer: D\" (Wrong ‚Äì lacks ### D ###)\n",
        "üö´ Incorrect: \"### A ### because first we multiply...\" (Wrong ‚Äì reasoning must come before the answer)\n",
        "\n",
        "‚ö†Ô∏è WARNING:\n",
        "\n",
        "Do NOT reveal the final answer early.\n",
        "Your reasoning must always appear BEFORE the ### X ### format answer.\n",
        "If you fail to follow this format, your response will be considered invalid.\n",
        "Now, solve the problem step by step before revealing the answer:\n",
        "\"\"\"\n",
        "deep_seek_prompt = \"\"\"You are a mathematical assistant. Your goal is to provide the final answer in the correct format.\n",
        "\n",
        "### Question\n",
        "{question}\n",
        "\n",
        "### Options\n",
        "{options}\n",
        "\n",
        "### **Formatting Rules:**\n",
        "- Place the **final answer** inside `### ###` at the **end** of your response.\n",
        "- Inside `### ###`, include **only** the letter of the selected option (e.g., `### B ###`, `### E ###`).\n",
        "- **Do not place the answer at the beginning or in the middle of your response.**\n",
        "\n",
        "### **Correct Output Examples:**\n",
        "‚úÖ `\"After analyzing the question carefully... [EXPLANATION] ... The final answer is ### D ###.\"`\n",
        "‚úÖ `\"By applying the correct formula, we find the correct choice: ### A ###.\"`\n",
        "\n",
        "### **Incorrect Output Examples:**\n",
        "üö´ `\"The correct answer is ### C ###. Here‚Äôs why...\"` (‚ùå Wrong: answer must come last)\n",
        "üö´ `\"Step 1: Solve... Step 2: Compute... Answer: D\"` (‚ùå Wrong: lacks `### D ###`)\n",
        "üö´ `\"### A ### is the correct choice because...\"` (‚ùå Wrong: reasoning must come first)\n",
        "\n",
        "**Now, provide your response while ensuring the answer follows the correct format.**\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwqXvQgIx2v0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def query_ollama(prompt_template: str, question: str, options: list, model: str, correct_answer: str, ollama_url: str):\n",
        "    \"\"\"\n",
        "    Queries an Ollama model with a given strict prompt and evaluates its response.\n",
        "\n",
        "    Args:\n",
        "        prompt_template (str): The template containing the prompt format.\n",
        "        question (str): The GMAT-style question.\n",
        "        options (list): A list of multiple-choice options.\n",
        "        model (str): The name of the Ollama model.\n",
        "        correct_answer (str): The correct answer (e.g., \"E\").\n",
        "        ollama_url (str): The base URL of the Ollama instance.\n",
        "\n",
        "    Returns:\n",
        "        dict: JSON containing the model's response, extracted answer, and correctness.\n",
        "    \"\"\"\n",
        "\n",
        "    # Format the strict prompt with the given question and options\n",
        "    formatted_prompt = prompt_template.format(question=question, options=\"\\n\".join([f\"{chr(65 + i)}) {opt}\" for i, opt in enumerate(options)]))\n",
        "\n",
        "    url = f\"{ollama_url}/api/generate\"\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"prompt\": formatted_prompt,\n",
        "        \"temperature\": 0.05,  # Lower temperature for more deterministic responses\n",
        "        \"stream\": False  # Disable streaming for easier parsing\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Send request to Ollama API\n",
        "        response = requests.post(url, json=payload, verify=False)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            model_output = response.json().get(\"response\", \"\").strip()\n",
        "\n",
        "            # Extract answer inside ### ###\n",
        "            match = re.search(r\"###\\s*([A-E])\\s*###\", model_output)  # Ensure only A-E answers are extracted\n",
        "            model_answer = match.group(1) if match else None  # Extracted answer or None if not found\n",
        "\n",
        "            # Check correctness\n",
        "            is_correct = model_answer.upper() == correct_answer.upper() if model_answer else False\n",
        "\n",
        "            return {\n",
        "                \"model_output\": model_output,\n",
        "                \"model_answer\": model_answer,\n",
        "                \"is_correct\": is_correct,\n",
        "                \"correct_answer\": correct_answer,\n",
        "                \"model\": model,\n",
        "                \"prompt_used\": formatted_prompt\n",
        "            }\n",
        "        else:\n",
        "            return {\"error\": \"Failed to query Ollama\", \"status_code\": response.status_code}\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return {\"error\": f\"Request failed: {e}\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVT4Bu5Lx2v1",
        "outputId": "0fe72863-c7f1-4a17-b477-17446d171a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If (x^2 + 4x - 11)/5 ‚â§ x + 1, then x could be represented by which of the following?\n",
            "A\n"
          ]
        }
      ],
      "source": [
        "row = dataset[\"train\"][6]\n",
        "row.keys()\n",
        "print(row[\"question\"])\n",
        "print(row[\"correct\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PC8mumjx2v1",
        "outputId": "8caf60ab-4481-4ba9-ffaa-74a4b665b498"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_output': \"Step 1: First, we need to solve the inequality `(x^2 + 4x - 11)/5 ‚â§ x + 1`. Let's start by moving all terms to one side of the inequality:\\n\\n`x^2 + 4x - 11/5 - (5x + 5) ‚â§ 0`\\n\\nStep 2: Simplify the equation:\\n\\n`x^2 - x - 26/5 ‚â§ 0`\\n\\nStep 3: Now, solve this quadratic inequality. First, let's find the roots by solving `x^2 - x - 26/5 = 0`. We can use the quadratic formula:\\n\\nFor any equation of form `ax^2 + bx + c = 0`, its roots are given by `(b ¬± sqrt(b^2-4ac))/2a`.\\n\\nHere, a = 1, b = -1, and c = -26/5.\\n\\nSo the roots will be:\\n\\n`x = (1 ¬± sqrt((-1)^2-4*1*(-26/5)))/2`\\n\\n`x = (1 ¬± sqrt(1+104/5))/2`\\n\\n`x = (1 ¬± sqrt((5 + 104)/5))/2`\\n\\n`x = (1 ¬± sqrt(109/5))/2`\\n\\nStep 4: Now, we have the roots `sqrt(109/5)` and `-sqrt(109/5)`. This means that the inequality holds for values of x between these two points because a quadratic expression changes sign at its roots.\\n\\nStep 5: Converting the square root back to decimal or simplifying further:\\n\\n`x = (1 ¬± sqrt(109))/2` \\n\\nThis gives us `sqrt(109)` approximately equals `10.4`, and hence, `(sqrt(109) - 1)/2 ‚âà (10.4 - 1)/2 = 4.7`, which is slightly less than our threshold.\\n\\nThe other root (`(-sqrt(109))/2`) gives us the value for when `x` starts becoming negative as `x` decreases below this point.\\n\\nHence, from Step 3 onwards:\\n\\nThe inequality `(x^2 + 4x - 11)/5 ‚â§ x + 1` holds true for values of `x` that are between `-sqrt(109)/2` and `(sqrt(109) - 1)/2`, which means it's in the range `-approx. 4.7` to approximately `3`.\\n\\nStep 6: Matching with our options:\\n\\nThe only option representing this range is **D** `‚àí 4 ‚â§ x ‚â§ ‚àí 3`.\\n\\nFinal answer: ### D ###\",\n",
              " 'model_answer': 'D',\n",
              " 'is_correct': False,\n",
              " 'correct_answer': 'A',\n",
              " 'model': 'qwen2:7b',\n",
              " 'prompt_used': '\\nYou are a helpful mathematical assistant. Your goal is to **explain the reasoning behind your answer step-by-step before revealing the final answer**.\\n\\n### **Follow these rules carefully:**\\n- **First, break the problem down into logical, structured steps.**\\n- **Explain your thought process clearly and concisely before stating the final answer.**\\n- **At the end of your response, provide the final answer enclosed in `### ###`.**\\n- **Inside `### ###`, include only the letter of the selected option (e.g., `### B ###`, `### E ###`).**\\n- **The answer must ALWAYS be the last thing you output.**\\n- **Do NOT state or hint at the final answer before reaching the conclusion.**\\n\\n---\\n\\n### **Question**  \\nIf (x^2 + 4x - 11)/5 ‚â§ x + 1, then x could be represented by which of the following?  \\n\\n### **Options**  \\nA) A)‚àí 3 ‚â§ x ‚â§ 4\\nB) B)‚àí 4 ‚â§ x ‚â§ 3\\nC) C)‚àí 3 ‚â§ x ‚â§ 3\\nD) D)‚àí 4 ‚â§ x ‚â§ ‚àí 3\\nE) E)3 ‚â§ x ‚â§ 4  \\n\\n---\\n\\n### **Allowed Output Format (Example):**  \\n‚úÖ **Correct:**  \\n```plaintext\\nStep 1: Identify the key values from the question.  \\nStep 2: Apply the correct mathematical formula.  \\nStep 3: Compute the result and match it with the given options.  \\nStep 4: Verify the correctness.  \\n\\nFinal answer: ### D ###\\nüö´ Incorrect: \"The correct answer is ### C ###. Here‚Äôs why...\" (Wrong ‚Äì answer must come last)\\nüö´ Incorrect: \"Step 1: Solve... Step 2: Compute... Answer: D\" (Wrong ‚Äì lacks ### D ###)\\nüö´ Incorrect: \"### A ### because first we multiply...\" (Wrong ‚Äì reasoning must come before the answer)\\n\\n‚ö†Ô∏è WARNING:\\n\\nDo NOT reveal the final answer early.\\nYour reasoning must always appear BEFORE the ### X ### format answer.\\nIf you fail to follow this format, your response will be considered invalid.\\nNow, solve the problem step by step before revealing the answer:\\n'}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_ollama(prompt_reasoning, row[\"question\"], row[\"options\"],   \"qwen2:7b\", row[\"correct\"], url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iV2Tlj-x2v1"
      },
      "outputs": [],
      "source": [
        "prompts = [prompt_reasoning, prompt_strict]\n",
        "questions = list(dataset[\"train\"])\n",
        "math_models = [\n",
        "\"qwen2-math:latest\",\n",
        "\"wizard-math:latest\",\n",
        "\"mathstral:latest\",]\n",
        "sampled_questions = random.sample(questions, 150)\n",
        "models =[\"gemma2:9b\"]# [\"phi3:latest\", \"mistral-nemo:latest\", \"llama33:latest\", \"phi4:latest\"] # [\"deepseek-r1:7b\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2h5gpBH0x2v1"
      },
      "outputs": [],
      "source": [
        "sampled_questions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj1agypax2v2"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "for model in models:\n",
        "    print(model)\n",
        "    for t in tqdm(sampled_questions):\n",
        "        for prompt in tqdm(prompts):\n",
        "            answer = query_ollama(prompt, t[\"question\"], t[\"options\"], model, t[\"correct\"], url)\n",
        "            answers.append(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T86JV3BFx2v2"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(answers)\n",
        "df.to_excel(\"results_math_gemma.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiYvo9HMx2v2"
      },
      "outputs": [],
      "source": [
        "prompts = [prompt_reasoning, prompt_strict]\n",
        "questions = list(dataset[\"train\"])\n",
        "\n",
        "sampled_questions = random.sample(questions, 150)\n",
        "models =[\"deepseek-r1:7b\",\"deepseek-math:latest\",]\n",
        "answers = []\n",
        "for model in models:\n",
        "    print(model)\n",
        "    for t in tqdm(sampled_questions):\n",
        "            answer = query_ollama(deep_seek_prompt, t[\"question\"], t[\"options\"], model, t[\"correct\"], url)\n",
        "            answers.append(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhT0nml4x2v2"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(answers)\n",
        "df.to_excel(\"results_2402.xlsx\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}